# –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É: /home/obn7/NovBase/core/cognition.py

import time
import re
import os
import json
import asyncio
import datetime
import subprocess
from typing import Dict, Any, Optional

# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (–ë–µ–∫–∞–ø-—Å–∏—Å—Ç–µ–º–∞)
try:
    from .sync_guard import SyncGuard
except ImportError:
    SyncGuard = None

# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–≥–æ —Å–ª–æ—è (NovBase Standard)
try:
    from .mid_cognition.modules.input_analyzer import input_analyzer
    from .mid_cognition.modules.meta_reasoner import meta_reasoner
    from .mid_cognition.modules.planner import mission_planner
    
    # –†–µ–ø–µ—Ç–∏—Ç–æ—Ä (–§–æ—Ä–º–∞)
    from .mid_cognition.modules.linguistic_tutor import LinguisticTutor
    linguistic_tutor = LinguisticTutor()
    
    # –≠–º–æ—Ü–∏–∏ (–•–∞—Ä–∞–∫—Ç–µ—Ä)
    from .mid_cognition.modules.emotional_core import EmotionalCore
    emotional_core = EmotionalCore()
    
    # –°–∏–Ω—Ç–∞–∫—Å–∏—Å (–ì–æ–ª–æ—Å–æ–≤–æ–π –≤–≤–æ–¥)
    from .mid_cognition.modules.syntactic_restorer import SyntacticRestorer
    syntax_restorer = SyntacticRestorer()
    
except ImportError:
    input_analyzer = meta_reasoner = mission_planner = None
    linguistic_tutor = emotional_core = syntax_restorer = None

# --- –ö–õ–ê–°–° "–¢–†–ò –ê–ü–û–°–¢–û–õ–ê" (–¶–ï–ù–¢–†–ê–õ–ò–ó–û–í–ê–ù–ù–´–ô –û–†–ö–ï–°–¢–†–ê–¢–û–†) ---
class TriApostles:
    def __init__(self, engine):
        self.engine = engine
        self.facts_path = os.path.join(engine.cache_secure_dir, "apostles_facts.json")
        self.actions_cfg_path = os.path.join(engine.base_path, "configs/actions.json")
        self.user_facts = self._load_facts()

    def _load_facts(self):
        if os.path.exists(self.facts_path):
            try:
                with open(self.facts_path, "r", encoding="utf-8") as f:
                    return json.load(f)
            except: return {}
        return {}

    def _save_facts(self):
        try:
            with open(self.facts_path, "w", encoding="utf-8") as f:
                json.dump(self.user_facts, f, ensure_ascii=False, indent=2)
            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –±–µ–∫–∞–ø–∞ –ø–æ—Å–ª–µ –∑–∞–ø–∏—Å–∏
            if self.engine.guard:
                self.engine.guard.synchronize()
        except Exception as e:
            print(f"‚ö†Ô∏è [Apostles Save Error]: {e}")

    def process(self, text: str) -> Optional[str]:
        """–û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è: –î–µ–π—Å—Ç–≤–∏–µ -> –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ -> –ó–∞–ø–∏—Å—å."""
        t_lower = text.lower().strip()
        
        # 1. –ê–ü–û–°–¢–û–õ –î–ï–ô–°–¢–í–ò–Ø (Action): –ü–µ—Ä–µ—Ö–≤–∞—Ç —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∫–æ–º–∞–Ω–¥
        action_triggers = ["–≤—ã–ø–æ–ª–Ω–∏", "—Å–¥–µ–ª–∞–π", "–ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏", "–æ—á–∏—Å—Ç–∏", "–∑–∞–ø—É—Å—Ç–∏", "–±–µ–∫–∞–ø", "—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–π"]
        if any(trigger in t_lower for trigger in action_triggers):
            action_res = self._handle_action(t_lower)
            if action_res: return action_res

        # 2. –ê–ü–û–°–¢–û–õ –ü–£–¢–ò (Recall): –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
        recall_triggers = ["—á—Ç–æ —Ç—ã –∑–∞–ø–æ–º–Ω–∏–ª", "–ø–æ–≤—Ç–æ—Ä–∏", "–Ω–∞–ø–æ–º–Ω–∏", "–∫–∞–∫–æ–π", "–∫–∞–∫–æ–µ", "–Ω–∞–∑–æ–≤–∏", "—Ä–∞—Å—Å–∫–∞–∂–∏ —á—Ç–æ –∑–∞–ø–æ–º–Ω–∏–ª"]
        if any(phrase in t_lower for phrase in recall_triggers):
            return self._handle_recall(t_lower)

        # 3. –ê–ü–û–°–¢–û–õ –í–•–û–î–ê (Store): –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–∏–≥–≥–µ—Ä–∞ –∑–∞–ø–∏—Å–∏ –≤ –ø–∞–º—è—Ç—å
        if "–∑–∞–ø–æ–º–Ω–∏" in t_lower:
            return self._handle_store(text, t_lower)
            
        return None

    def _handle_action(self, t_lower: str) -> Optional[str]:
        """–õ–æ–≥–∏–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∫–æ–º–∞–Ω–¥ —á–µ—Ä–µ–∑ –±–µ–ª—ã–π —Å–ø–∏—Å–æ–∫."""
        if not os.path.exists(self.actions_cfg_path):
            return None 

        try:
            with open(self.actions_cfg_path, 'r') as f:
                whitelist = json.load(f)
        except: return "‚ö†Ô∏è [–ê–ø–æ—Å—Ç–æ–ª –î–µ–π—Å—Ç–≤–∏—è]: –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è configs/actions.json"

        cmd_key = None
        if "–ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏" in t_lower or "—Ä–µ—Å—Ç–∞—Ä—Ç" in t_lower: cmd_key = "reboot_node"
        elif "–±–µ–∫–∞–ø" in t_lower or "—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–π" in t_lower: cmd_key = "sync_memory"
        elif "–æ—á–∏—Å—Ç–∏ –ª–æ–≥–∏" in t_lower: cmd_key = "clean_logs"
        elif "deploy" in t_lower or "–¥–µ–ø–ª–æ–π" in t_lower: cmd_key = "deploy_fix"

        if cmd_key and cmd_key in whitelist:
            command = whitelist[cmd_key]
            try:
                subprocess.Popen(command.split(), stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                return f"‚öôÔ∏è [–ê–ø–æ—Å—Ç–æ–ª –î–µ–π—Å—Ç–≤–∏—è]: –ó–∞–¥–∞—á–∞ **{cmd_key}** –∑–∞–ø—É—â–µ–Ω–∞."
            except Exception as e:
                return f"‚ùå [–ê–ø–æ—Å—Ç–æ–ª –î–µ–π—Å—Ç–≤–∏—è]: –°–±–æ–π –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}"
        return None

    def _handle_store(self, text: str, t_lower: str) -> str:
        cat, val = "note", ""
        if "—á–∏—Å–ª–æ" in t_lower or "—Ü–∏—Ñ—Ä" in t_lower:
            nums = re.findall(r"\d+", text)
            cat, val = "number", nums[0] if nums else ""
        elif "–∏–º—è" in t_lower:
            parts = text.split("–∏–º—è", 1)
            val = parts[1].strip().split()[0] if len(parts) > 1 else ""
            cat = "name"
        else:
            parts = text.split("–∑–∞–ø–æ–º–Ω–∏", 1)
            val = parts[1].strip().lstrip(": ") if len(parts) > 1 else ""
            cat = "note"

        if val:
            self.user_facts[cat] = val
            self._save_facts()
            return f"‚úÖ [–ê–ø–æ—Å—Ç–æ–ª –í—ã—Ö–æ–¥–∞]: –ó–∞–ø–æ–º–Ω–∏–ª {cat}: **{val}**."
        return "‚ö†Ô∏è [–ê–ø–æ—Å—Ç–æ–ª –í—Ö–æ–¥–∞]: –ù–µ—á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å."

    def _handle_recall(self, t_lower: str) -> str:
        cat = "note"
        if "—á–∏—Å–ª–æ" in t_lower: cat = "number"
        elif "–∏–º—è" in t_lower: cat = "name"
        
        val = self.user_facts.get(cat)
        if val:
            return f"üì¢ [–ê–ø–æ—Å—Ç–æ–ª –í—ã—Ö–æ–¥–∞]: –í –ø–∞–º—è—Ç–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {cat}: **{val}**."
        
        if self.user_facts.get("note"):
            return f"–í '{cat}' –ø—É—Å—Ç–æ, –Ω–æ –µ—Å—Ç—å –∑–∞–º–µ—Ç–∫–∞: **{self.user_facts.get('note')}**."
        return f"–ü–∞–º—è—Ç—å –ø—É—Å—Ç–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {cat}."

# --- –û–°–ù–û–í–ù–û–ô –î–í–ò–ñ–û–ö ---
class MidCognitionEngine:
    def __init__(self):
        self.base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.cache_local = os.path.join(self.base_path, "storage/cache.json")
        self.cache_secure_dir = os.path.expanduser("~/.novbase_protected_memory")
        self.cache_secure = os.path.join(self.cache_secure_dir, "master_cache.json")
        
        os.makedirs(os.path.dirname(self.cache_local), exist_ok=True)
        os.makedirs(self.cache_secure_dir, exist_ok=True)

        self.apostles = TriApostles(self)

        if SyncGuard:
            self.guard = SyncGuard(
                primary_paths=[self.cache_secure, self.cache_local, self.apostles.facts_path],
                backup_dir=os.path.join(self.cache_secure_dir, "shadow_vault")
            )
            self.guard.restore_integrity()
        else:
            self.guard = None

        self.cache_data = self._load_secured_cache()
        self._cache_lock = asyncio.Lock()
        
        print(f"‚úÖ –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π —Ü–µ–Ω—Ç—Ä 10.6 –∑–∞–ø—É—â–µ–Ω. –í—Å–µ —Å–∏—Å—Ç–µ–º—ã –∞–∫—Ç–∏–≤–Ω—ã.")

    def _load_secured_cache(self) -> Dict[str, Any]:
        for path in [self.cache_secure, self.cache_local]:
            if os.path.exists(path):
                try:
                    with open(path, "r", encoding="utf-8") as f:
                        return json.load(f)
                except Exception: continue
        return {}

    async def force_sync_cache(self):
        async with self._cache_lock:
            try:
                data_str = json.dumps(self.cache_data, ensure_ascii=False, indent=2)
                with open(self.cache_local, "w", encoding="utf-8") as f: f.write(data_str)
                with open(self.cache_secure, "w", encoding="utf-8") as f: f.write(data_str)
                if self.guard: self.guard.synchronize()
            except Exception as e: print(f"‚ö†Ô∏è [Cache Sync Error] {e}")

    def analyze_input(self, text: str, **kwargs) -> Dict[str, Any]:
        processed_text = syntax_restorer.preprocess_voice_flow(text) if syntax_restorer else text

        apostle_response = self.apostles.process(processed_text)
        if apostle_response:
            return {"intent": "command_intercept", "semantic_block": apostle_response}

        if processed_text in self.cache_data:
            return {"intent": "cache_hit", "response": self.cache_data[processed_text]["value"]}

        if input_analyzer:
            analysis = input_analyzer.analyze(processed_text)
        else:
            analysis = {"intent": "unknown", "sentiment": "neutral"}
        
        analysis["raw_text"] = processed_text 
        analysis["semantic_block"] = self._priority_semantic_check(processed_text)
        
        if meta_reasoner:
            analysis["reasoning"] = meta_reasoner.analyze(processed_text, analysis=analysis, last_obj=kwargs.get('last_obj', '–Ω–∏—á–µ–≥–æ'))
        
        return analysis

    def _priority_semantic_check(self, text: str) -> str:
        t = text.lower()
        if any(cmd in t for cmd in ["—Å–æ—Ö—Ä–∞–Ω–∏", "–∑–∞–ø–∏—à–∏"]) and "/root" in t:
            return "–î–æ—Å—Ç—É–ø –∫ —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—É—Ç—è–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –¥–ª—è —Ç–≤–æ–µ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏."
        return None

    def create_system_prompt(self, analysis: Dict[str, Any]) -> str:
        if analysis.get("intent") == "command_intercept":
            return analysis["semantic_block"]

        tutor_logic = linguistic_tutor.get_instruction() if linguistic_tutor else ""
        emotion_logic = emotional_core.get_instruction(analysis) if emotional_core else ""
        
        return (
            "–¢—ã ‚Äî –ú–∞–ª—ã—à, –ø—Ä–∞–≥–º–∞—Ç–∏—á–Ω—ã–π –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã–π –º–æ–¥—É–ª—å NovBase.\n"
            f"{tutor_logic}\n{emotion_logic}\n"
            "–°–¢–ò–õ–¨: –ö—Ä–∞—Ç–∫–æ, –∏–Ω–∂–µ–Ω–µ—Ä–Ω—ã–π –ø–æ–¥—Ö–æ–¥. –û–±—Ä–∞—â–∞–π—Å—è –∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Ç–æ–ª—å–∫–æ –Ω–∞ '—Ç—ã'."
        )
